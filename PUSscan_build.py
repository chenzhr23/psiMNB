# -*- coding: utf-8 -*-
"""
build MNB model for PUS-dependent psi prediction.

reference: 
    1. https://www.kaggle.com/code/singhakash/dna-sequencing-with-machine-learning
    2. https://iq.opengenus.org/text-classification-naive-bayes/
"""

import os
import sys
import pandas as pd# pip install openpyxl
import matplotlib.pyplot as plt
import numpy as np
import pickle
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, precision_score, recall_score
import argparse

# Define command line arguments
parser = argparse.ArgumentParser(description='predict PUS-targeting observation by constructing psiMNB model.')
parser.add_argument('-training_file', metavar='FILE', type=str, help='training file selected by humans/oracles (can be generated by findMotif module of psiFinder)')
parser.add_argument('-model_name', metavar='FILE', type=str, help='model name to be loaded')
parser.add_argument('-to_predict', metavar='FILE', type=str, help='file to be predicted')
parser.add_argument('-output_dir', metavar='OUTPUT_DIR', type=str, help='output file name to be saved')

# Parse the arguments
args = parser.parse_args()

# Check that required arguments are provided
if not args.training_file:
    parser.error('the -training_file FILE argument for training file is required')
if not args.model_name:
    parser.error('the -model_name FILE argument for model name is required')
if not args.to_predict:
    parser.error('the -to_predict FILE argument for ready-to-be-predicted file is required')
if not args.output_dir:
    parser.error('the -output_dir FILE argument for output dir is required')

training_file = args.training_file
model_name = args.model_name
to_predict = args.to_predict
output_dir = args.output_dir

# Check if directory exists and is writable
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
elif not os.access(output_dir, os.W_OK):
    raise PermissionError("Output directory is not writable")

# Display help if no arguments provided
if len(sys.argv)==1:
    parser.print_help()
    sys.exit(1)

human_rna = pd.read_csv(training_file,sep="\t")
human_rna.head()

human_rna['class'].value_counts().sort_index().plot.bar()
plt.title("Class distribution of input PUS")
# Save the figure
plt.savefig(os.path.join(output_dir, model_name+'_class_distribution.png') )

####build model####
#convert our training data sequences into short overlapping k-mers of length 4. 
def Kmers_funct(seq, size=4):
    return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]

human_rna['words'] = human_rna.apply(lambda x: Kmers_funct(x['Y_extendSeq_20nt']), axis=1)
human_rna = human_rna.drop('Y_extendSeq_20nt', axis=1)

human_rna.head()

human_texts = list(human_rna['words'])
for item in range(len(human_texts)):
    human_texts[item] = ' '.join(human_texts[item])
    
#separate labels
y_human = human_rna.iloc[:, 0].values # y_human for human_rna
y_human


cv = CountVectorizer(ngram_range=(1,1),min_df=5)#The n-gram size of (x,x) is previously determined by testing
X_human = cv.fit_transform(human_texts)
print(X_human.shape)

# Splitting the human dataset into the training set and test set
X_train, X_test, y_train, y_test = train_test_split(X_human, 
                                                    y_human, 
                                                    test_size = 0.20, 
                                                    random_state=42)

classifier = MultinomialNB(alpha=0.1)
classifier.fit(X_train, y_train)
with open(os.path.join(output_dir, model_name+'_multinomialnb_model.pkl'), 'wb') as f:
    pickle.dump([cv, classifier], f)
y_pred = classifier.predict(X_test)

print("Confusion matrix for predictions on human test RNA sequence\n")
print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))
def get_metrics(y_test, y_predicted):
    accuracy = accuracy_score(y_test, y_predicted)
    precision = precision_score(y_test, y_predicted, average='weighted')
    recall = recall_score(y_test, y_predicted, average='weighted')
    f1 = f1_score(y_test, y_predicted, average='weighted')
    mcc = matthews_corrcoef(y_test, y_predicted)
    return accuracy, precision, recall, f1, mcc
accuracy, precision, recall, f1, mcc = get_metrics(y_test, y_pred)
print("accuracy = %.3f \nprecision = %.3f \nrecall = %.3f \nf1 = %.3f \nmcc = %.3f" % (accuracy, precision, recall, f1, mcc))


####preform prediction####
with open(os.path.join(output_dir, model_name+'_multinomialnb_model.pkl'), 'rb') as f:
    cv, classifier = pickle.load(f)

to_pred = pd.read_csv(to_predict,sep="\t")
to_pred.head()
words = to_pred.apply(lambda x: Kmers_funct(x['Y_extendSeq_20nt']), axis=1)

for item in range(len(words)):
    words[item] = ' '.join(words[item])

to_pred_seq_cv = cv.transform(words)
predicted_label = classifier.predict(to_pred_seq_cv)
unique, counts = np.unique(predicted_label, return_counts=True)
print(dict(zip(unique, counts)))
predicted_proba = classifier.predict_proba(to_pred_seq_cv)

def compare(row):
  max_val = row.max()
  max_col = row.idxmax()
  return max_col

predicted_proba_df = pd.DataFrame(predicted_proba, columns=list(classifier.classes_))
predicted_proba_df['PUS-targeting'] = predicted_proba_df.apply(compare, axis=1)
to_pred = pd.concat([to_pred, predicted_proba_df], axis=1)
# to_pred.to_excel(os.path.join(output_dir, model_name+"_prediction.xlsx"),index=False)
to_pred.to_csv(os.path.join(output_dir, model_name+"_model_prediction.txt"), sep="\t", index=False)
